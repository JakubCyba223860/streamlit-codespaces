{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import time\n",
    "\n",
    "def measure_runtime(predict_func, data):\n",
    "    start_time = time.time()\n",
    "    _ = predict_func(data)  # Call the prediction function\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    return runtime\n",
    "\n",
    "class TestModelPerformance:\n",
    "    def setup_method(self, method):\n",
    "        # Retrieve the data from the stored variables\n",
    "        self.data = X  # Replace X with your actual data\n",
    "        self.target = y  # Replace y with your actual target\n",
    "        self.predictions = model.predict(X)  # Replace model with your actual model\n",
    "\n",
    "    def test_data_shape(self):\n",
    "        # Ensure the data has the expected shape\n",
    "        assert self.data.shape == (7232, 40)\n",
    "        assert self.target.shape == (7232, 3)\n",
    "\n",
    "    def test_X_columns(self):\n",
    "        # Ensure the data has the expected columns\n",
    "        expected_x_columns = ['ResponseTimeScore', 'SlowResponseTimePenalty', 'NuisanceReportsCriminal',\n",
    "            'NuisanceReportsNonCriminal', 'lbm', 'afw', 'fys', 'onv', 'soc', 'vrz', 'won', 'Migrated',\n",
    "            'NetLaborParticipation', 'FlexibleContracts', 'SelfContract', 'PopulationEduLow',\n",
    "            'PopulationEduMedium', 'PopulationEduHigh', 'y0-15%', 'y15-25%', 'y65-%',\n",
    "            'Peoplewithmigrationbackgroud%', 'Averagepeopleperhousehold', 'Populationdensitykm2',\n",
    "            'AverageWOZ-valueofhouses(x1000euro)', 'Percentuninhabited(%)', 'Rentalproperies(%)',\n",
    "            'Tradeandcatering%', 'Culture/recreationproperies%', 'Carsperhousehold', 'UrbanityLevel',\n",
    "            'Inhabitants', 'Benches', 'Lights', 'POI', 'DayC', 'NightC', 'Rain Days', 'Rainfall(mm)',\n",
    "            'Daylight hours']\n",
    "        assert list(self.data.columns) == expected_x_columns\n",
    "\n",
    "    def test_y_columns(self):\n",
    "        # Ensure the data has the expected columns\n",
    "        expected_y_columns = ['PropertyCrimesPerThousandInhabitants', 'ViolentCrimesPerThousandInhabitants',\n",
    "            'BurglaryCrimesPerThousandInhabitants']\n",
    "        assert list(self.target.columns) == expected_y_columns\n",
    "\n",
    "    def test_data_duplicates(self):\n",
    "        # Ensure there are no duplicate rows in the data\n",
    "        duplicates = self.data.duplicated().sum()\n",
    "        assert duplicates == 0\n",
    "\n",
    "    def test_data_missing_values(self):\n",
    "        # Ensure there are no missing values in the data\n",
    "        missing_values = self.data.isnull().sum().sum()\n",
    "        assert missing_values == 0\n",
    "\n",
    "    def test_model_mean_absolute_error(self):\n",
    "        # Calculate mean absolute error between predictions and actual target values\n",
    "        mae = mean_absolute_error(self.target, self.predictions)\n",
    "        np.testing.assert_almost_equal(mae, 0.001, decimal=2)\n",
    "\n",
    "    def test_model_mean_squared_error(self):\n",
    "        # Calculate mean squared error between predictions and actual target values\n",
    "        mse = mean_squared_error(self.target, self.predictions)\n",
    "        np.testing.assert_almost_equal(mse, 0.001, decimal=2)\n",
    "\n",
    "    def test_model_r2_score(self):\n",
    "        # Calculate R-squared score between predictions and target\n",
    "        r2 = r2_score(self.target, self.predictions)\n",
    "        assert r2 >= 0.9\n",
    "\n",
    "    def test_model_maximum_error(self):\n",
    "        # Calculate maximum absolute error between predictions and actual target values\n",
    "        max_error = np.max(np.abs(self.target - self.predictions), axis=0)\n",
    "        threshold = 2\n",
    "        np.testing.assert_array_less(max_error, threshold)\n",
    "\n",
    "    def test_model_explained_variance(self):\n",
    "        # Calculate the percentage of explained variance by the model\n",
    "        explained_variance = r2_score(self.target, self.predictions)\n",
    "        assert explained_variance >= 0.9\n",
    "\n",
    "    def test_model_prediction_consistency(self):\n",
    "        # Re-run the model predictions and assert that the predictions remain the same\n",
    "        new_predictions = model.predict(X)  # Replace model with your actual model\n",
    "        np.testing.assert_array_equal(self.predictions, new_predictions)\n",
    "\n",
    "    def test_model_runtime(self):\n",
    "        # Measure the time taken by the model to make predictions on a sample dataset\n",
    "        sample_data = self.data[:100]\n",
    "        runtime = measure_runtime(model.predict, sample_data)  # Replace model with your actual model\n",
    "        assert runtime < 5\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
